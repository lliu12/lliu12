<div class="row g-5 mb-5">
  <div>
    <h3 class="fw-bold border-bottom pb-3 mb-5">Research</h3>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <!-- <img src="images/adhoc.png" alt="hpp" style="border-style: none" width="200"> -->
            <img src = "https://github.com/lliu12/kirigami_sim/blob/master/media/penrose_expansion.gif" width="100"/>
            <img src = "https://github.com/lliu12/kirigami_sim/blob/master/media/penrose_hamiltonian.gif" width="100"/> 
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <p>Liu, L., Choi, G., & Mahadevan, L. Wallpaper group kirigami. Proceedings of the Royal Society A. 477, 20210161, 2021.</p>
            [
            <a href="https://arxiv.org/abs/2104.13399">Paper</a> /
            <!-- <a href="https://www.youtube.com/watch?v=Fd4RcVaNthY">Video</a> / -->
            <a href="https://github.com/lliu12/kirigami_sim">Code</a> ]
            <!-- <b><p style="color:red">Won best paper award at NeurIPS 2020 Cooperative AI Workshop!</p></b> -->
            <!-- <p>We develop Bayesian Delegation, a decentralized multi-agent learning mechanism that enables agents to rapidly infer the sub-tasks of others by inverse planning. We demonstrate that our model is a capable ad-hoc collaborator, scales with team size and makes inferences about intent similar to human observers.</p> -->
          </td>
        </tr>

        <!-- <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/hpp.png" alt="hpp" style="border-style: none" width="200">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2003.06906">
              <papertitle>Model-based Reinforcement Learning for Multiagent Goal Alignment</papertitle>
            </a>
            <br>
            <strong>Rose E. Wang</strong>,
            <a href="https://research.google/people/JChaseKew/">J.Chase Kew</a>,
            <a href="https://scholar.google.com/citations?user=vOLXDDAAAAAJ&hl=en">Dennis Lee</a>,
            <a href="https://deepai.org/profile/tsang-wei-edward-lee">Tsang-Wei Edward Lee</a>,
            <a href="https://research.google/people/TingnanZhang/">Tingnan Zhang</a>,
            <a href="http://brianichter.com/">Brian Ichter</a>,
            <a href="http://www.jie-tan.net/">Jie Tan</a>,
            <a href="https://www.afaust.info/">Aleksandra Faust</a>
            <br>
            <em>Conference on Robot Learning (CoRL) 2020</em>.<br>
            <em>Mentioned in <a href="https://ai.googleblog.com/2021/01/google-research-looking-back-at-2020.html">Google AI Year in Review, 2020</a>.</em><br> 
            <br>
              [
            <a href="https://arxiv.org/abs/2003.06906">Paper</a> /
            <a href="https://www.youtube.com/watch?v=-LqgfksqNH8&feature=youtu.be">Video</a> /
            <a href="https://sites.google.com/view/multiagent-hpp">Project Page</a> / 
            <a href="https://ai.googleblog.com/2021/04/model-based-rl-for-decentralized-multi.html">Blog post</a>
            ]
            <br>
            <p></p>
            <p>In this work, we present hierarchical predictive planning (HPP) for decentralized multiagent navigation tasks. Our approach is trained in simulation and works in unseen settings both in simulation and in the real world (zero shot transfer)!</p>
          </td>
        </tr> -->

      </tbody></table>

    </td>
  </tr>
  </table>
  </div>
</div>


<!-- <div class="row g-5 mb-5">
  <div>
    <h3 class="fw-bold border-bottom pb-3 mb-5">Publications</h3>
    {% if page.title == "Home" %}
      {% for item in site.data.publications.featured %}
        <p><a href="{{ item.url }}">{{ item.name }}</a></p>
      {% endfor %}
    {% else %}
      {% for item in site.data.publications.index %}
        <p><a href="{{ item.url }}">{{ item.name }}</a></p>
      {% endfor %}
    {% endif %}
  </div>
</div> -->
